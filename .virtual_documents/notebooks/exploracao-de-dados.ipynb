














import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split, GridSearchCV

from ydata_profiling import ProfileReport





renda = pd.read_csv('../data/raw/previsao_de_renda.csv').drop('Unnamed: 0', axis=1)
renda.head(5)





prof = ProfileReport(renda, explorative=True, minimal=True)
prof


prof.to_file('../reports/renda_analisys.html')








id_duplicados = [id for id in renda['id_cliente'].value_counts().index if renda['id_cliente'].value_counts()[id] != 1]
count_id_Duplicados = renda.loc[renda['id_cliente'].isin(id_duplicados)].sort_values(by='id_cliente').groupby('data_ref')['id_cliente'].count()
count_id_Totais = renda.groupby('data_ref')['id_cliente'].count()

print('='*80)
print('Total de ID por data de registro na base de dados:')
print('='*80)
print(count_id_Totais)
print('='*80)
print('Total de ID duplicados por data de registro na base de dados:')
print('='*80)
print(count_id_Duplicados)
print('='*80)
print('Total de ID únicos por data de registro na base de dados:')
print('='*80)
print(count_id_Totais - count_id_Duplicados)


renda.loc[renda['id_cliente'].isin(id_duplicados)].sort_values(by='id_cliente').head(5)





renda['data_ref'] = pd.to_datetime(renda['data_ref'])
renda['data_ref']

















def calcular_entropia(tab_freq):
    h = 0
    for classe in tab_freq.index:
        h += tab_freq[classe] * np.log2(tab_freq[classe])
    return h * -1

def calcular_entropia_maxima(tab_freq):
    return np.log2(len(tab_freq))


taxas_entropia_antes = dict()

for col in renda.select_dtypes(include=['object', 'bool']).columns:
    tab = renda[col].value_counts() / len(renda[col])
    h = calcular_entropia(tab)
    h_max = calcular_entropia_maxima(tab)
    tx_h = (h / h_max) * 100
    taxas_entropia_antes[col] = tx_h
    print('A entropia da variável {} é {:.2f} com seu máximo de entropia sendo {:.2f}'.format(col, h, h_max))
    print('Taxa de Entropia {:.2f}%'.format(tx_h))
    print()








renda.info()





df = renda.dropna(axis=0).drop_duplicates(subset='id_cliente')
df.info()





df.corr(numeric_only=True)['qtd_filhos']['qt_pessoas_residencia'] * 100








df['tam_familia'] = ''
df.loc[(df['qtd_filhos'] == 0) & (df['qt_pessoas_residencia'] == 1.0), 'tam_familia'] = 'Mínima'
df.loc[(df['qtd_filhos'] != 0) & (df['qt_pessoas_residencia'] == 1.0), 'tam_familia'] = 'Pequena'
df.loc[(df['qtd_filhos'] >= 0) & (df['qt_pessoas_residencia'] > 1.0) & (df['qt_pessoas_residencia'] <= 3.0), 'tam_familia'] = 'Pequena'
df.loc[(df['qtd_filhos'] >= 0) & (df['qt_pessoas_residencia'] > 3.0) & (df['qt_pessoas_residencia'] <= 5.0), 'tam_familia'] = 'Média'
df.loc[(df['qtd_filhos'] >= 0) & (df['qt_pessoas_residencia'] > 5.0), 'tam_familia'] = 'Grande'
df[['qtd_filhos', 'qt_pessoas_residencia', 'tam_familia']]





tab = df['tam_familia'].value_counts() / len(df['tam_familia'])
taxas_entropia_antes['tam_familia'] = (calcular_entropia(tab) / calcular_entropia_maxima(tab)) * 100
print('A entropia da nova variável tam_familia é de {:.2f} e seu máximo de entropia é {:.2f}'.format(calcular_entropia(tab), 
                                                                                                     calcular_entropia_maxima(tab)))
print('Taxa de Entropia {:.2f}%'.format(taxas_entropia_antes['tam_familia']))


prof = ProfileReport(df, explorative=True, minimal=True)
prof


prof.to_file('../reports/renda_analisys_clean.html')





for col in df.select_dtypes(include=['object', 'bool']).columns:
    tab = df[col].value_counts() / len(df[col])
    h = calcular_entropia(tab)
    h_max = calcular_entropia_maxima(tab)
    tx_h = (h / h_max) * 100
    print('A entropia da variável {} é de {:.2f} e seu máximo de entropia é {:.2f}'.format(col, h, h_max))
    print('Taxa de Entropia Atual {:.2f}%'.format(tx_h))
    print('Taxa de Entropia Anterior {:.2f}%'.format(taxas_entropia_antes[col]))
    print('Diferença: {:.2f}%'.format(tx_h - taxas_entropia_antes[col]))
    print()





df['sexo'] = df['sexo'].map({'F': 1, 'M': 0})
df['posse_de_veiculo'] = df['posse_de_veiculo'].astype(np.int64)
df['posse_de_imovel'] = df['posse_de_imovel'].astype(np.int64)
df['qt_pessoas_residencia'] = df['qt_pessoas_residencia'].astype(np.int64)

df.head(5)





%matplotlib inline
sns.set_style('whitegrid')
sns.heatmap(data=pd.get_dummies(data=df).drop(labels=[col for col in df.columns], errors='ignore', axis=1).corr(), cmap='crest')
plt.show()





corr = pd.get_dummies(data=df).drop(labels=[col for col in df.columns], errors='ignore', axis=1).corr()
values0 = dict()
values = dict()

for col in corr:
    values0[col] = ([(corr[col].index[corr[col] == item].tolist()[0], item) for item in corr[col] if (item > 0.5) or (item < -0.5)])

for key in values0.keys():
    if len(values0[key]) != 1:
        values[key] = [item for item in values0[key] if item[1] != 1.0]

for key in values.keys():
    print('A classe {} tem correlações com:'.format(key))
    for c, v in values[key]:
        print('> {} igual a {}'.format(c, v))
    print()





sns.heatmap(data=pd.get_dummies(data=df).corr(), cmap='crest')
plt.show()





corr = pd.get_dummies(data=df).corr()
values0 = dict()
values = dict()

for col in corr:
    values0[col] = ([(corr[col].index[corr[col] == item].tolist()[0], item) for item in corr[col] if (item > 0.5) or (item < -0.5)])

for key in values0.keys():
    if len(values0[key]) != 1:
        values[key] = [item for item in values0[key] if item[1] != 1.0]

for key in values.keys():
    print('A classe/variável {} tem correlações com:'.format(key))
    for c, v in values[key]:
        print('> {} igual a {}'.format(c, v))
    print()





pd.get_dummies(data=df).assign(renda = df['renda']).corr()['renda']





fig, ax = plt.subplots()
sns.barplot(pd.get_dummies(data=df)
            .drop(labels=[col for col in df.columns], errors='ignore', axis=1)
            .assign(renda = df['renda'])
            .corr()
            .drop('renda', axis=0)['renda'], ax=ax)
ax.set_xticks(ax.get_xticks())
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
ax.set_yticks(ticks=np.arange(-.3, 1.1, .1))
ax.set_ylabel('Correlação com Renda')
plt.title('Correlação das Classes com a Variável Renda')
plt.show()





fig, ax = plt.subplots()
sns.barplot(pd.get_dummies(data=df).corr()['renda'].drop('renda', axis=0), ax=ax)
ax.set_xticks(ax.get_xticks())
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
ax.set_yticks(ticks=np.arange(-.3, 1.1, .1))
ax.set_ylabel('Correlação com Renda')
plt.title('Correlação das Variáveis com Renda')
plt.show()





df = df.drop('tipo_residencia', axis=1)
df.head(5)





df = df.drop('data_ref', axis=1).set_index('id_cliente', drop=True)
dummies = pd.get_dummies(df[['tipo_renda', 'educacao', 'estado_civil', 'tam_familia']], dtype=np.int64)
data = pd.concat([df.drop(['tipo_renda', 'educacao', 'estado_civil', 'tam_familia'], axis=1), dummies], axis=1)
data.head(5)


X = data.drop('renda', axis=1)
y = data['renda']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=412)

print(f'Tamanho base de treino: {X_train.shape[0]} amostras\nTamanho base de teste: {X_test.shape[0]} amostras')


reg0 = DecisionTreeRegressor(random_state=412).fit(X_train, y_train)

path0 = reg0.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas0 = {'ccp_alpha': path0.ccp_alphas}

grid_search = GridSearchCV(estimator=reg, 
                           param_grid=ccp_alphas, 
                           cv=15, 
                           verbose=2, 
                           scoring='r2')

grid_search.fit(X_train, y_train)


results = pd.DataFrame(grid_search.cv_results_)
results.iloc[grid_search.best_index_]['mean_test_score']


kfold_best_tree = DecisionTreeRegressor(random_state=412, 
                                        min_samples_leaf=int(X_train.shape[0]*.01), 
                                        min_samples_split=int(X_train.shape[0]*.05),
                                        ccp_alpha=results.iloc[grid_search.best_index_].params['ccp_alpha']).fit(X_train, y_train)

kbt_train_score = kfold_best_tree.score(X_train, y_train)
kbt_test_score = kfold_best_tree.score(X_test, y_test)

print(f'Acurácia na base de treino {kbt_train_score*100:.2f}%')
print(f'Acurácia na base de teste {kbt_test_score*100:.2f}%')





reg = DecisionTreeRegressor(random_state=412).fit(X_train, y_train)

path = reg.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas = path.ccp_alphas[::10]

regs = list()

for ccp_alpha in ccp_alphas:
    tree = DecisionTreeRegressor(random_state=412, ccp_alpha=ccp_alpha).fit(X_train, y_train)
    regs.append(tree)

train_scores = [reg.score(X_train, y_train) for reg in regs]
test_scores = [reg.score(X_test, y_test) for reg in regs]

print(f'Acurácia na base de treino {max(train_scores)*100:.2f}%')
print(f'Acurácia na base de teste {max(test_scores)*100:.2f}%')





sns.set_style('darkgrid')

fig, ax = plt.subplots()

ax.set_ylabel('Acurácia')
ax.set_xlabel('Alpha')
ax.set_title('Acurácia x Alpha nas Bases')

sns.lineplot(x=ccp_alphas, y=train_scores, drawstyle='steps-post', marker='o', label='Treino', ax=ax)
sns.lineplot(x=ccp_alphas, y=test_scores, drawstyle='steps-post', marker='o', label='Teste', ax=ax)

plt.show()





regular_best_tree = DecisionTreeRegressor(random_state=412, 
                                          ccp_alpha=ccp_alphas[test_scores.index(max(test_scores))]).fit(X_train, y_train)

rbt_train_score = regular_best_tree.score(X_train, y_train)
rbt_test_score = regular_best_tree.score(X_test, y_test)


print('Resultados')
print('='*80)
print(f'Melhor Árvore Treinada Normalmente Avaliada na Base de Treino: {rbt_train_score*100:.2f}%')
print(f'Melhor Árvore Treinada Normalmente Avaliada na Base de Teste: {rbt_test_score*100:.2f}%')
print(f'Melhor Árvore Treinada K-Fold Avaliada na Base de Treino: {kbt_train_score*100:.2f}%')
print(f'Melhor Árvore Treinada K-Fold Avaliada na Base de Teste: {kbt_test_score*100:.2f}%')








top5 = pd.DataFrame({'name': regular_best_tree.feature_names_in_, 'importance': regular_best_tree.feature_importances_}).iloc[:5]['name']

X_train_ajs = (X_train[top5]
               .assign(qtd_filhos = df['qtd_filhos'])
               .assign(qt_pessoas_residencia = df['qt_pessoas_residencia'])
               .assign(casado = classes_estado_civil.Casado)
               .assign(separado = classes_estado_civil.Separado)
               .assign(solteiro = classes_estado_civil.Solteiro)
               .assign(uniao = classes_estado_civil.União)
               .assign(viuvo = classes_estado_civil.Viúvo)
               .assign(grande = classes_tam_familia.Grande)
               .assign(media = classes_tam_familia.Média)
               .assign(minima = classes_tam_familia.Mínima)
               .assign(pequena = classes_tam_familia.Pequena)
              )

X_test_ajs = (X_test[top5]
               .assign(qtd_filhos = df['qtd_filhos'])
               .assign(qt_pessoas_residencia = df['qt_pessoas_residencia'])
               .assign(casado = classes_estado_civil.Casado)
               .assign(separado = classes_estado_civil.Separado)
               .assign(solteiro = classes_estado_civil.Solteiro)
               .assign(uniao = classes_estado_civil.União)
               .assign(viuvo = classes_estado_civil.Viúvo)
               .assign(grande = classes_tam_familia.Grande)
               .assign(media = classes_tam_familia.Média)
               .assign(minima = classes_tam_familia.Mínima)
               .assign(pequena = classes_tam_familia.Pequena)
              )

regAjs = DecisionTreeRegressor(random_state=412).fit(X_train_ajs, y_train)

pathAjs = regAjs.cost_complexity_pruning_path(X_train_ajs, y_train)
ccp_alphasAjs = pathAjs.ccp_alphas[::10]

regs = list()

for ccp_alpha in ccp_alphasAjs:
    tree = DecisionTreeRegressor(random_state=412, ccp_alpha=ccp_alpha).fit(X_train_ajs, y_train)
    regs.append(tree)

train_scores_ajs = [reg.score(X_train_ajs, y_train) for reg in regs]
test_scores_ajs = [reg.score(X_test_ajs, y_test) for reg in regs]

print(f'Acurácia na base de treino {max(train_scores_ajs)*100:.2f}%')
print(f'Acurácia na base de teste {max(test_scores_ajs)*100:.2f}%')








features = pd.DataFrame({'name': regular_best_tree.feature_names_in_, 
                         'importance_regular_tree': regular_best_tree.feature_importances_, 
                         'importance_kfold_tree': kfold_best_tree.feature_importances_})

vars = [features.loc[i, 'name'] for i in range(len(features)) if (features.loc[i, 'importance_regular_tree'] > 0) or (features.loc[i, 'importance_kfold_tree'] > 0)]
vars


















